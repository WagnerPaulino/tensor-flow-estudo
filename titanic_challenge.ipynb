{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.8)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.48.2)\n",
      "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->kaggle) (2.6)\n",
      "Downloading titanic.zip to data\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|███████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 354kB/s]\n",
      "Archive:  data/titanic.zip\n",
      "  inflating: data/titanic/gender_submission.csv  \n",
      "  inflating: data/titanic/test.csv   \n",
      "  inflating: data/titanic/train.csv  \n"
     ]
    }
   ],
   "source": [
    "! rm -rf data/titanic\n",
    "! rm -rf data/titanic.zip\n",
    "! pip install kaggle\n",
    "! kaggle competitions download -c titanic -p data/\n",
    "! unzip data/titanic.zip -d data/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZBNgfWxE387"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.special import logit\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def mapIsAlone(x):\n",
    "  if(x > 1):\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6SYeiERH5QE"
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"data/titanic/train.csv\",sep=\",\", encoding=\"ISO-8859-1\", low_memory=False,)\n",
    "test_set = pd.read_csv(\"data/titanic/test.csv\",sep=\",\", encoding=\"ISO-8859-1\", low_memory=False,)\n",
    "# Substituir os valores nulos\n",
    "train_set[\"Age\"].fillna(train_set[\"Age\"].median(), inplace = True)\n",
    "test_set[\"Age\"].fillna(test_set[\"Age\"].median(), inplace = True)\n",
    "test_set[\"Fare\"].fillna(test_set[\"Fare\"].median(), inplace = True)\n",
    "Embarked_mode=train_set['Embarked'].mode()[0]\n",
    "train_set[\"Embarked\"].fillna(\"S\", inplace = True)\n",
    "# Eliminar colunas desnecessarias\n",
    "train_set.drop(\"Cabin\", axis = 1, inplace = True)\n",
    "test_set.drop(\"Cabin\", axis = 1, inplace = True)\n",
    "train_set.drop([\"Name\",\"Ticket\"], axis = 1, inplace = True)\n",
    "test_set.drop([\"Name\",\"Ticket\"], axis = 1, inplace = True)\n",
    "\n",
    "# Categorizar numericamente\n",
    "train_set['Sex'] = train_set['Sex'].map({'female': 0, 'male': 1})\n",
    "test_set['Sex']= test_set['Sex'].map({'female': 0, 'male': 1})\n",
    "train_set['Embarked'] = train_set['Embarked'].map({'S': 0, 'C': 1,'Q': 2})\n",
    "test_set['Embarked']= test_set['Embarked'].map({'S': 0, 'C': 1,'Q': 2})\n",
    "# Eliminas redundâncias\n",
    "train_set[\"Family\"] = train_set[\"SibSp\"] + train_set[\"Parch\"] + 1\n",
    "test_set[\"Family\"] = test_set[\"SibSp\"] + test_set[\"Parch\"] + 1\n",
    "train_set[\"IsAlone\"] = train_set[\"Family\"].map(mapIsAlone)\n",
    "test_set[\"IsAlone\"] = test_set[\"Family\"].map(mapIsAlone)\n",
    "\n",
    "train_set=train_set.drop([\"Family\"],axis=1)\n",
    "test_set=test_set.drop([\"Family\"],axis=1)\n",
    "train_set=train_set.drop([\"SibSp\",\"Parch\"],axis=1)\n",
    "test_set=test_set.drop([\"SibSp\",\"Parch\"],axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_set[['Age','Fare']] = scaler.fit_transform(train_set[['Age','Fare']])\n",
    "test_set[['Age','Fare']] = scaler.transform(test_set[['Age','Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bG9F_P0PLKsp"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = train_set.corr()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "sns.heatmap(corr,vmax=0.9,square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "xgwhsLryMhCM",
    "outputId": "496f27da-6fa9-430e-eca8-8fbd00a5b69b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.0\n",
       "Survived       0.0\n",
       "Pclass         0.0\n",
       "Sex            0.0\n",
       "Age            0.0\n",
       "Fare           0.0\n",
       "Embarked       0.0\n",
       "IsAlone        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "lWO-ez9OO0O8",
    "outputId": "f53f1d0b-fb29-47cd-afec-68266d1303f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.0\n",
       "Pclass         0.0\n",
       "Sex            0.0\n",
       "Age            0.0\n",
       "Fare           0.0\n",
       "Embarked       0.0\n",
       "IsAlone        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Md5nKcYhfK7D",
    "outputId": "5b8c0822-28aa-43cb-856d-251ecf36c2dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex       Age      Fare  Embarked  IsAlone\n",
       "0            1         0       3    1 -0.565736 -0.502445         0        0\n",
       "1            2         1       1    0  0.663861  0.786845         1        0\n",
       "2            3         1       3    0 -0.258337 -0.488854         0        1\n",
       "3            4         1       1    0  0.433312  0.420730         0        0\n",
       "4            5         0       3    1  0.433312 -0.486337         0        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jwnZjV6wMRG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsAlone  Survived\n",
       "0        0  0.505650\n",
       "1        1  0.303538"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-JDaraj6j2xo",
    "outputId": "8f7d2b7e-b650-4d89-cf82-5d4167c3e797"
   },
   "outputs": [],
   "source": [
    "X_train = train_set.drop(['Survived','PassengerId'], axis=1)\n",
    "y_train = train_set[\"Survived\"]\n",
    "X_test  = test_set.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Mgk4yTvjkxG_",
    "outputId": "486193f9-9271-4c44-95af-babfdb9832cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age      Fare  Embarked  IsAlone\n",
       "0       3    1 -0.565736 -0.502445         0        0\n",
       "1       1    0  0.663861  0.786845         1        0\n",
       "2       3    0 -0.258337 -0.488854         0        1\n",
       "3       1    0  0.433312  0.420730         0        0\n",
       "4       3    1  0.433312 -0.486337         0        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "BiE6GVBLk0Am",
    "outputId": "6f1df3c2-19c4-4858-f605-6b5ced965d6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "bx-uMKUuk3Me",
    "outputId": "1f16bc1e-2a43-4a31-98f1-95ea26c07437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.394887</td>\n",
       "      <td>-0.490783</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.355510</td>\n",
       "      <td>-0.507479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.508257</td>\n",
       "      <td>-0.453367</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.181487</td>\n",
       "      <td>-0.474005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>-0.401017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age      Fare  Embarked  IsAlone\n",
       "0       3    1  0.394887 -0.490783         2        1\n",
       "1       3    0  1.355510 -0.507479         0        0\n",
       "2       2    1  2.508257 -0.453367         2        1\n",
       "3       3    1 -0.181487 -0.474005         0        1\n",
       "4       3    0 -0.565736 -0.401017         0        0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AlURJCA4ljBp",
    "outputId": "391a2caa-a436-444b-f03d-b29bc13727d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 6) for input Tensor(\"input_1:0\", shape=(None, None, 6), dtype=float32), but it was called on an input with incompatible shape (None, 6).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 6) for input Tensor(\"input_1:0\", shape=(None, None, 6), dtype=float32), but it was called on an input with incompatible shape (None, 6).\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7138\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7845\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7935\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7957\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8126\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.8047\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8171\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8238\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8193\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8283\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.8114\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8215\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8215\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8227\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8305\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8328\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8294\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8159\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8283\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8328\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8249\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8260\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8373\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8249\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8440\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8272\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8249\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8316\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8384\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8204\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8350\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8328\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8440\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8339\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8305\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8361\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8395\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8294\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8328\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8429\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8451\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8350\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8429\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8384\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3534 - accuracy: 0.8418\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8474\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3622 - accuracy: 0.8418\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8496\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8429\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8395\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8339\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8451\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8406\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8519\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8451\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8474\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8406\n",
      "Epoch 58/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8361\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8406\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8519\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8519\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8608\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8440\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8429\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3432 - accuracy: 0.8418\n",
      "Epoch 66/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3396 - accuracy: 0.8496\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3387 - accuracy: 0.8563\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.3361 - accuracy: 0.8406\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8586\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8406\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8507\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8440\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8451\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8440\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.3376 - accuracy: 0.8451\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3305 - accuracy: 0.8507\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8620\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3210 - accuracy: 0.8507\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8552\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8474\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8485\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3403 - accuracy: 0.8474\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8519\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8485\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3218 - accuracy: 0.8563\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8552\n",
      "Epoch 87/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3216 - accuracy: 0.8620\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3130 - accuracy: 0.8507\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3207 - accuracy: 0.8496\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8721\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3160 - accuracy: 0.8608\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8552\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.8563\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.8608\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3157 - accuracy: 0.8563\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8552\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.8552\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8552\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3154 - accuracy: 0.8608\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3068 - accuracy: 0.8541\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8653\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8507\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8586\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.8552\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3025 - accuracy: 0.8676\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8541\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3117 - accuracy: 0.8709\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8664\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8653\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8631\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3087 - accuracy: 0.8698\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8653\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8631\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8698\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8642\n",
      "Epoch 116/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8664\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8541\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2964 - accuracy: 0.8687\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8631\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8698\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.8721\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2969 - accuracy: 0.8687\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.8676\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2853 - accuracy: 0.8709\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.8608\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8676\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.8709\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.8642\n",
      "Epoch 129/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3133 - accuracy: 0.8597\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.8620\n",
      "Epoch 131/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.8709\n",
      "Epoch 132/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8698\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.8709\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8709\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2890 - accuracy: 0.8687\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2884 - accuracy: 0.8743\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.8698\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3014 - accuracy: 0.8676\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.8732\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2788 - accuracy: 0.8833\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8676\n",
      "Epoch 142/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2828 - accuracy: 0.8709\n",
      "Epoch 143/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.8844\n",
      "Epoch 144/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2854 - accuracy: 0.8765\n",
      "Epoch 145/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.8799\n",
      "Epoch 146/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.8698\n",
      "Epoch 147/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.8743\n",
      "Epoch 148/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8664\n",
      "Epoch 149/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.8732\n",
      "Epoch 150/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2823 - accuracy: 0.8676\n",
      "Epoch 151/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.8676\n",
      "Epoch 152/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8721\n",
      "Epoch 153/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8799\n",
      "Epoch 154/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2829 - accuracy: 0.8664\n",
      "Epoch 155/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2758 - accuracy: 0.8754\n",
      "Epoch 156/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2808 - accuracy: 0.8788\n",
      "Epoch 157/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.8698\n",
      "Epoch 158/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2855 - accuracy: 0.8732\n",
      "Epoch 159/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2952 - accuracy: 0.8743\n",
      "Epoch 160/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8698\n",
      "Epoch 161/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.8833\n",
      "Epoch 162/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8799\n",
      "Epoch 163/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8822\n",
      "Epoch 164/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.8765\n",
      "Epoch 165/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2662 - accuracy: 0.8822\n",
      "Epoch 166/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2598 - accuracy: 0.8833\n",
      "Epoch 167/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.8822\n",
      "Epoch 168/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2890 - accuracy: 0.8721\n",
      "Epoch 169/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8765\n",
      "Epoch 170/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2707 - accuracy: 0.8810\n",
      "Epoch 171/300\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.8878\n",
      "Epoch 172/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8822\n",
      "Epoch 173/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2679 - accuracy: 0.8833\n",
      "Epoch 174/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2854 - accuracy: 0.8743\n",
      "Epoch 175/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.8810\n",
      "Epoch 176/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.8956\n",
      "Epoch 177/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2677 - accuracy: 0.8799\n",
      "Epoch 178/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2659 - accuracy: 0.8765\n",
      "Epoch 179/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.8866\n",
      "Epoch 180/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.8855\n",
      "Epoch 181/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.8765\n",
      "Epoch 182/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2806 - accuracy: 0.8698\n",
      "Epoch 183/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2707 - accuracy: 0.8810\n",
      "Epoch 184/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2619 - accuracy: 0.8866\n",
      "Epoch 185/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.8956\n",
      "Epoch 186/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2608 - accuracy: 0.8878\n",
      "Epoch 187/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.8844\n",
      "Epoch 188/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.8900\n",
      "Epoch 189/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2672 - accuracy: 0.8822\n",
      "Epoch 190/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2532 - accuracy: 0.8900\n",
      "Epoch 191/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2646 - accuracy: 0.8911\n",
      "Epoch 192/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.8822\n",
      "Epoch 193/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2691 - accuracy: 0.8810\n",
      "Epoch 194/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2723 - accuracy: 0.8777\n",
      "Epoch 195/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2766 - accuracy: 0.8799\n",
      "Epoch 196/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2583 - accuracy: 0.8878\n",
      "Epoch 197/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2635 - accuracy: 0.8878\n",
      "Epoch 198/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2636 - accuracy: 0.8911\n",
      "Epoch 199/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2726 - accuracy: 0.8844\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.8923\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2647 - accuracy: 0.8844\n",
      "Epoch 202/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2667 - accuracy: 0.8765\n",
      "Epoch 203/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2713 - accuracy: 0.8810\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2563 - accuracy: 0.8878\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2517 - accuracy: 0.8923\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2458 - accuracy: 0.8923\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2442 - accuracy: 0.8956\n",
      "Epoch 208/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2466 - accuracy: 0.8911\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.8833\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2539 - accuracy: 0.8911\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2532 - accuracy: 0.8833\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2535 - accuracy: 0.8900\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2488 - accuracy: 0.8979\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2426 - accuracy: 0.8990\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2490 - accuracy: 0.8878\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.8956\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.8855\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2539 - accuracy: 0.8911\n",
      "Epoch 219/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2579 - accuracy: 0.8822\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2458 - accuracy: 0.8956\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2428 - accuracy: 0.8923\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2597 - accuracy: 0.8855\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2411 - accuracy: 0.9024\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "      if(logs.get('accuracy')>=0.9):\n",
    "          self.model.stop_training = True\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(None,6)),\n",
    "  tf.keras.layers.Dense(512,activation=tf.keras.activations.relu),\n",
    "  tf.keras.layers.Dense(1024,activation=tf.keras.activations.relu),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(512,activation=tf.keras.activations.relu),\n",
    "  tf.keras.layers.Dense(1,activation=tf.keras.activations.sigmoid)\n",
    "\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=300, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pMFjrZkmnoDy",
    "outputId": "b5bd1ced-6847-4a42-a04a-4386a24d7f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 6) for input Tensor(\"input_1:0\", shape=(None, None, 6), dtype=float32), but it was called on an input with incompatible shape (None, 6).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.09193945e-03],\n",
       "       [4.97074798e-05],\n",
       "       [5.34949111e-16],\n",
       "       [8.75259042e-02],\n",
       "       [4.36198771e-01],\n",
       "       [1.57514453e-01],\n",
       "       [2.57197291e-01],\n",
       "       [1.11523569e-02],\n",
       "       [3.21320951e-01],\n",
       "       [6.85010036e-07],\n",
       "       [9.21455324e-02],\n",
       "       [5.70530713e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.16802647e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.84232613e-05],\n",
       "       [3.75089765e-01],\n",
       "       [1.44762874e-01],\n",
       "       [6.02483749e-04],\n",
       "       [3.72505605e-01],\n",
       "       [9.98406053e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999344e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.54554186e-09],\n",
       "       [1.00000000e+00],\n",
       "       [2.25838959e-01],\n",
       "       [9.28181469e-01],\n",
       "       [2.97363460e-01],\n",
       "       [4.52401849e-07],\n",
       "       [7.52955675e-04],\n",
       "       [8.90103340e-01],\n",
       "       [2.20260024e-03],\n",
       "       [8.73474300e-01],\n",
       "       [4.87170815e-01],\n",
       "       [4.04779673e-01],\n",
       "       [5.72845280e-01],\n",
       "       [5.58122396e-02],\n",
       "       [5.95671475e-01],\n",
       "       [1.30526787e-05],\n",
       "       [4.36636031e-01],\n",
       "       [1.06090158e-01],\n",
       "       [9.99819875e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.51037395e-02],\n",
       "       [3.63652378e-01],\n",
       "       [1.04158551e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.86016035e-01],\n",
       "       [8.49309564e-03],\n",
       "       [4.57409531e-01],\n",
       "       [9.99809742e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.61343259e-01],\n",
       "       [1.94702952e-05],\n",
       "       [1.24443352e-01],\n",
       "       [6.72526956e-02],\n",
       "       [6.25282526e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.00396109e-02],\n",
       "       [2.57176846e-01],\n",
       "       [7.78002441e-02],\n",
       "       [5.66343188e-01],\n",
       "       [1.65224075e-04],\n",
       "       [9.99493957e-01],\n",
       "       [4.25676495e-01],\n",
       "       [8.08374680e-05],\n",
       "       [5.10280609e-01],\n",
       "       [1.00000000e+00],\n",
       "       [7.12920129e-01],\n",
       "       [4.36893404e-02],\n",
       "       [1.75446361e-01],\n",
       "       [1.27221376e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.65435113e-13],\n",
       "       [9.11838710e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.81125939e-01],\n",
       "       [7.12920129e-01],\n",
       "       [8.48778009e-01],\n",
       "       [6.74128532e-04],\n",
       "       [6.81940258e-01],\n",
       "       [9.21455324e-02],\n",
       "       [1.09197266e-04],\n",
       "       [3.55862737e-01],\n",
       "       [7.98759103e-01],\n",
       "       [5.68326950e-01],\n",
       "       [7.98537850e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.87177575e-01],\n",
       "       [9.29052532e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.11838710e-02],\n",
       "       [9.62828875e-01],\n",
       "       [6.59809709e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.25037611e-01],\n",
       "       [5.76810122e-01],\n",
       "       [1.38047099e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.87134874e-02],\n",
       "       [1.04158551e-01],\n",
       "       [7.84867406e-02],\n",
       "       [5.23292780e-01],\n",
       "       [5.09930551e-02],\n",
       "       [8.93962383e-03],\n",
       "       [1.04158551e-01],\n",
       "       [8.72330368e-02],\n",
       "       [1.08621001e-01],\n",
       "       [1.17552876e-02],\n",
       "       [7.98588037e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.29039627e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.84789461e-01],\n",
       "       [1.05433345e-01],\n",
       "       [5.44394672e-01],\n",
       "       [2.06725001e-02],\n",
       "       [9.95089769e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.82957169e-08],\n",
       "       [1.00000000e+00],\n",
       "       [1.12317979e-01],\n",
       "       [1.04158551e-01],\n",
       "       [6.20445609e-02],\n",
       "       [4.52972353e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.52725160e-01],\n",
       "       [5.55762053e-02],\n",
       "       [1.47707880e-01],\n",
       "       [1.92193091e-02],\n",
       "       [5.08576632e-04],\n",
       "       [2.49738077e-05],\n",
       "       [1.00393772e-01],\n",
       "       [5.71238399e-02],\n",
       "       [1.10801786e-01],\n",
       "       [4.81975675e-02],\n",
       "       [5.52760303e-01],\n",
       "       [2.76166201e-08],\n",
       "       [1.42385852e-06],\n",
       "       [1.00000000e+00],\n",
       "       [4.81465356e-09],\n",
       "       [9.33301449e-02],\n",
       "       [9.61625397e-01],\n",
       "       [4.19020653e-04],\n",
       "       [8.08328390e-04],\n",
       "       [4.31032181e-02],\n",
       "       [4.36636031e-01],\n",
       "       [2.89207041e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.09307140e-01],\n",
       "       [4.85802775e-05],\n",
       "       [9.66284633e-01],\n",
       "       [1.98122159e-08],\n",
       "       [5.96093833e-02],\n",
       "       [1.00000000e+00],\n",
       "       [5.54446459e-01],\n",
       "       [9.61625338e-01],\n",
       "       [6.24953985e-01],\n",
       "       [7.98509240e-01],\n",
       "       [8.66162956e-01],\n",
       "       [8.97966981e-01],\n",
       "       [9.73397195e-02],\n",
       "       [1.56120300e-01],\n",
       "       [5.93203306e-03],\n",
       "       [8.58699679e-02],\n",
       "       [2.24016650e-09],\n",
       "       [1.00000000e+00],\n",
       "       [5.63085973e-01],\n",
       "       [9.42617655e-02],\n",
       "       [1.07708156e-01],\n",
       "       [9.15127993e-03],\n",
       "       [1.07720852e-01],\n",
       "       [8.62669708e-07],\n",
       "       [9.62262869e-01],\n",
       "       [9.56486702e-01],\n",
       "       [2.09624946e-01],\n",
       "       [9.99997139e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.81125939e-01],\n",
       "       [3.37863386e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.04158551e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.67008728e-01],\n",
       "       [9.99783814e-01],\n",
       "       [3.33369374e-02],\n",
       "       [1.59167339e-05],\n",
       "       [1.59686625e-01],\n",
       "       [1.19363248e-01],\n",
       "       [4.25506115e-01],\n",
       "       [9.41179752e-01],\n",
       "       [1.42038218e-14],\n",
       "       [9.99941647e-01],\n",
       "       [1.37738734e-01],\n",
       "       [9.99893308e-01],\n",
       "       [5.69200397e-01],\n",
       "       [1.24366581e-02],\n",
       "       [4.05461818e-01],\n",
       "       [9.02398944e-01],\n",
       "       [7.33565450e-01],\n",
       "       [1.09494913e-11],\n",
       "       [1.00000000e+00],\n",
       "       [1.10746622e-02],\n",
       "       [9.61113870e-02],\n",
       "       [2.12374330e-03],\n",
       "       [9.56383348e-03],\n",
       "       [1.00000000e+00],\n",
       "       [6.52993023e-02],\n",
       "       [9.94791090e-02],\n",
       "       [9.71110463e-02],\n",
       "       [3.40938568e-04],\n",
       "       [1.00000000e+00],\n",
       "       [6.59858584e-02],\n",
       "       [1.45792961e-04],\n",
       "       [7.98759103e-01],\n",
       "       [7.77710497e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.11838710e-02],\n",
       "       [9.12209630e-01],\n",
       "       [4.17975783e-02],\n",
       "       [7.50679970e-01],\n",
       "       [4.49770689e-02],\n",
       "       [1.15882758e-05],\n",
       "       [1.84174180e-01],\n",
       "       [4.99290228e-02],\n",
       "       [7.98537850e-01],\n",
       "       [8.86008143e-02],\n",
       "       [1.77300125e-01],\n",
       "       [1.80552634e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.96712446e-02],\n",
       "       [1.04351014e-01],\n",
       "       [7.96448529e-01],\n",
       "       [4.90330756e-02],\n",
       "       [6.41192555e-01],\n",
       "       [4.66586441e-01],\n",
       "       [9.99999881e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.93327661e-06],\n",
       "       [7.71211147e-01],\n",
       "       [4.03736612e-06],\n",
       "       [9.21975672e-02],\n",
       "       [5.56540999e-06],\n",
       "       [5.30350804e-01],\n",
       "       [6.88517272e-01],\n",
       "       [1.76399946e-04],\n",
       "       [9.95089769e-01],\n",
       "       [1.27065808e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.78196442e-02],\n",
       "       [7.35824704e-02],\n",
       "       [4.65140343e-02],\n",
       "       [1.44630164e-01],\n",
       "       [9.42617655e-02],\n",
       "       [1.04158551e-01],\n",
       "       [1.10173017e-01],\n",
       "       [9.99946773e-01],\n",
       "       [4.52495217e-02],\n",
       "       [9.29921734e-05],\n",
       "       [4.42208052e-02],\n",
       "       [9.46479201e-01],\n",
       "       [6.01391971e-01],\n",
       "       [3.42852861e-01],\n",
       "       [9.21455324e-02],\n",
       "       [4.59620237e-15],\n",
       "       [9.42617655e-02],\n",
       "       [4.04779673e-01],\n",
       "       [7.82977343e-02],\n",
       "       [7.98484543e-05],\n",
       "       [1.04158551e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99987960e-01],\n",
       "       [1.07708156e-01],\n",
       "       [9.99527693e-01],\n",
       "       [4.66978848e-02],\n",
       "       [4.26262617e-04],\n",
       "       [1.09197795e-02],\n",
       "       [3.02631557e-02],\n",
       "       [5.47395349e-01],\n",
       "       [7.79477894e-01],\n",
       "       [7.98537850e-01],\n",
       "       [4.88634109e-01],\n",
       "       [4.38364267e-01],\n",
       "       [1.18930310e-01],\n",
       "       [9.60082114e-02],\n",
       "       [2.17705965e-04],\n",
       "       [1.07720852e-01],\n",
       "       [9.11838710e-02],\n",
       "       [6.01330638e-01],\n",
       "       [1.99327558e-01],\n",
       "       [1.07720852e-01],\n",
       "       [8.69363546e-04],\n",
       "       [1.19638592e-01],\n",
       "       [7.76358843e-02],\n",
       "       [1.00000000e+00],\n",
       "       [2.97363460e-01],\n",
       "       [3.57660651e-03],\n",
       "       [1.25195861e-01],\n",
       "       [1.47481233e-01],\n",
       "       [4.57561016e-01],\n",
       "       [2.79772757e-06],\n",
       "       [5.08388877e-02],\n",
       "       [7.98537850e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.12133741e-03],\n",
       "       [9.36586857e-01],\n",
       "       [1.59066916e-03],\n",
       "       [4.14580107e-04],\n",
       "       [6.40355051e-02],\n",
       "       [2.71747231e-01],\n",
       "       [9.41120088e-02],\n",
       "       [5.90592623e-04],\n",
       "       [1.00000000e+00],\n",
       "       [5.51426649e-01],\n",
       "       [5.21114956e-08],\n",
       "       [2.11027771e-01],\n",
       "       [9.24064815e-02],\n",
       "       [3.87609005e-04],\n",
       "       [7.84867406e-02],\n",
       "       [1.26702875e-01],\n",
       "       [4.81975675e-02],\n",
       "       [9.92484391e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.70253432e-02],\n",
       "       [9.70074773e-01],\n",
       "       [3.72573122e-05],\n",
       "       [2.24166125e-01],\n",
       "       [6.71146214e-02],\n",
       "       [9.99902248e-01],\n",
       "       [7.14483857e-01],\n",
       "       [1.07708156e-01],\n",
       "       [1.52496994e-01],\n",
       "       [9.21455324e-02],\n",
       "       [4.27625388e-01],\n",
       "       [2.38651872e-01],\n",
       "       [6.55251942e-09],\n",
       "       [4.39659059e-02],\n",
       "       [1.07720852e-01],\n",
       "       [1.29869372e-01],\n",
       "       [1.47319973e-01],\n",
       "       [1.24072575e-11],\n",
       "       [1.00000000e+00],\n",
       "       [1.83871388e-03],\n",
       "       [4.72405046e-01],\n",
       "       [4.81975675e-02],\n",
       "       [1.09275877e-02],\n",
       "       [2.27692425e-02],\n",
       "       [9.99976635e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.10746622e-02],\n",
       "       [6.60866499e-04],\n",
       "       [1.28977990e-06],\n",
       "       [4.12691712e-01],\n",
       "       [7.03527331e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.22496021e-02],\n",
       "       [1.04158551e-01],\n",
       "       [6.49328649e-01],\n",
       "       [1.28411984e-13],\n",
       "       [1.00000000e+00],\n",
       "       [9.99976635e-01],\n",
       "       [8.75259042e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.59167339e-05],\n",
       "       [3.56413126e-01],\n",
       "       [4.78828430e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.18568581e-01],\n",
       "       [1.11950719e-07],\n",
       "       [1.00000000e+00],\n",
       "       [6.19962762e-12],\n",
       "       [1.37302279e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.19434029e-01],\n",
       "       [8.42027068e-02],\n",
       "       [1.07942476e-04],\n",
       "       [2.92963505e-01],\n",
       "       [1.04158551e-01],\n",
       "       [1.01982236e-01],\n",
       "       [7.80022860e-01],\n",
       "       [1.18989408e-01],\n",
       "       [7.87977278e-02],\n",
       "       [9.99824524e-01],\n",
       "       [5.77639043e-02],\n",
       "       [1.54495507e-01],\n",
       "       [8.96847248e-03],\n",
       "       [6.93353236e-01],\n",
       "       [2.08284305e-08],\n",
       "       [1.00000000e+00],\n",
       "       [5.19742370e-02],\n",
       "       [5.70003688e-02],\n",
       "       [2.20650072e-05],\n",
       "       [1.00000000e+00],\n",
       "       [7.02011287e-02],\n",
       "       [1.00000000e+00],\n",
       "       [4.54784334e-02],\n",
       "       [4.04829979e-02],\n",
       "       [1.00000000e+00],\n",
       "       [6.00202220e-05],\n",
       "       [1.00000000e+00],\n",
       "       [6.77209735e-01],\n",
       "       [2.96908297e-11],\n",
       "       [1.13275647e-03],\n",
       "       [2.84160890e-08],\n",
       "       [3.65029326e-11],\n",
       "       [7.98487782e-01],\n",
       "       [5.76516986e-01],\n",
       "       [7.98537850e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.60131240e-01],\n",
       "       [9.11838710e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.11918479e-01],\n",
       "       [9.11839008e-02],\n",
       "       [2.16544718e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "titanic_challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
